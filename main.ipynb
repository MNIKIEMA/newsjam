{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feaed337",
   "metadata": {},
   "source": [
    "## ONLY if running on Colaboratory, run this cell first (once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75f9491",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/pie3636/newsjam.git\n",
    "!mv newsjam/* ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad23b536",
   "metadata": {},
   "source": [
    "## Install missing modules if needed (only run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceafccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install -r requirements.txt\n",
    "!python -m spacy download fr_core_news_sm\n",
    "# Note: You'll have to restart the kernel/runtime after running this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6422ab",
   "metadata": {},
   "source": [
    "## Imports (only run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f9c5abd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PIL._binary'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11192/2018602333.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Our packages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrouge_l\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRougeLEval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbert_eval\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBERT_Eval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTimeEval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Downloads\\NLP\\Projet 703\\newsjam\\eval\\bert_eval.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mbert_score\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBERTScorer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# to create keyword reference summary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfr\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSTOP_WORDS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\bert_score\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0m__version__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"0.3.10\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mscorer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\bert_score\\score.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmpl_toolkits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes_grid1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_axes_locatable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m   2347\u001b[0m     \u001b[0mdict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"backend\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcsetup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_auto_backend_sentinel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2348\u001b[0m \u001b[1;31m# Set up the backend.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2349\u001b[1;33m \u001b[0mswitch_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"backend\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2351\u001b[0m \u001b[1;31m# Just to be safe.  Interactive mode can be turned on without\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mswitch_backend\u001b[1;34m(newbackend)\u001b[0m\n\u001b[0;32m    219\u001b[0m         else \"matplotlib.backends.backend_{}\".format(newbackend.lower()))\n\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m     \u001b[0mbackend_mod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbackend_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m     Backend = type(\n\u001b[0;32m    223\u001b[0m         \"Backend\", (matplotlib.backends._Backend,), vars(backend_mod))\n",
      "\u001b[1;32mc:\\program files\\python38\\lib\\importlib\\__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\matplotlib_inline\\backend_inline.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m from matplotlib.backends.backend_agg import (  # noqa\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mnew_figure_manager\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mFigureCanvasAgg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m_has_pil\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[0mbackend_version\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'v2.2'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0m_raise_version_warning\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m )\n\u001b[1;32m---> 58\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_binary\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mi32le\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_util\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeferred_error\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0misPath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'PIL._binary'"
     ]
    }
   ],
   "source": [
    "# MLSUM Corpus\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Loading article data\n",
    "import json\n",
    "\n",
    "# Our packages\n",
    "from eval.rouge_l import RougeLEval\n",
    "from eval.bert_eval import BERT_Eval\n",
    "from eval.time import TimeEval\n",
    "\n",
    "from summ.lsa import LSASummarizer\n",
    "from summ.bert_embed import BertEmbeddingsSummarizer\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "dataset = load_dataset('mlsum', 'fr')\n",
    "\n",
    "rouge_l = RougeLEval()\n",
    "bert = BERT_Eval()\n",
    "timer = TimeEval()\n",
    "lsa_summ = LSASummarizer()\n",
    "flaubert_summ = BertEmbeddingsSummarizer('flaubert/flaubert_large_cased')\n",
    "camembert_summ = BertEmbeddingsSummarizer('camembert/camembert-large')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e57dfaa",
   "metadata": {},
   "source": [
    "## Summarize a single article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3bdf0df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pick an article and its reference summary\n",
    "article = dataset['test']['text'][54]\n",
    "ref_summ = dataset['test']['summary'][54]\n",
    "\n",
    "# Computes the summary and evaluation\n",
    "# timer.evaluate_one(article, BertEmbeddingsSummarizer, 'camembert/camembert-large')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b30944c",
   "metadata": {},
   "source": [
    "## Summarize a series of articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cf57c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = dataset['test']['text'][:10]\n",
    "ref_summs = dataset['test']['summary'][:10]\n",
    "\n",
    "# Here we pick 5 articles\n",
    "# gen_summs = []\n",
    "# for text in tqdm(texts[:5]):\n",
    "#     gen_summs.append(flaubert_summ.get_summary(text))\n",
    "\n",
    "# scores1, scores2 = rouge_l.evaluate_many(ref_summs, gen_summs, 5)\n",
    "# results = rouge_l.get_results(scores1, scores2)\n",
    "\n",
    "# for k, v in results.items():\n",
    "#     print(k.ljust(25), round(v*100, 3), '%')\n",
    "\n",
    "timer.evaluate_many(texts, LSASummarizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bb0d4b",
   "metadata": {},
   "source": [
    "#### Optional: Save generated summaries to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8fa0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('generated.txt', 'w') as f:\n",
    "    for summ1, summ2 in tqdm(gen_summs):\n",
    "        f.write(summ1)\n",
    "        f.write('\\n\\n')\n",
    "        f.write(summ2)\n",
    "        f.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368b970a",
   "metadata": {},
   "source": [
    "## Summarize a series of scraped articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e78b51",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open('data/actu_preliminary.json', 'r', encoding='utf-8') as jsonfile:\n",
    "    data = json.load(jsonfile)\n",
    "\n",
    "texts = [article['text'] for article in data]\n",
    "ref_summs = [article['summary'] for article in data]\n",
    "\n",
    "gen_summs = []\n",
    "for text in tqdm(texts):\n",
    "    gen_summs.append(flaubert_summ.get_summary(text))\n",
    "\n",
    "scores1, scores2 = rouge_l.evaluate_many(ref_summs, gen_summs)\n",
    "results = rouge_l.get_results(scores1, scores2)\n",
    "\n",
    "for k, v in results.items():\n",
    "    print(k.ljust(25), round(v*100, 3), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b002dada",
   "metadata": {},
   "source": [
    "Implementation of BERTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643d3342",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_summs, short_summs, ref_summs, key_ref_sums =  bert.split_summs(gen_summs, ref_summs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0d9ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert.bert_score(long_summs, short_summs, ref_summs, key_ref_sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7715e238",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert.get_matrix(long_summs, ref_summs, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b3e2850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10589875",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"fr_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca78451a",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b5e3664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La zone du bâtiment municipal de Virginia Beach a été sécurisée. Kaitlin McKeown / AP Douze personnes ont été abattues vendredi 31 mai par un tireur dans un bâtiment municipal de Virginia Beach (Etat de Virginie), station balnéaire de la côte est américaine. Le bilan, dans un premier temps établi à 11 morts, a été revu à la hausse après le décès d’une victime qui « a succombé à ses blessures sur le chemin de l’hôpital », a détaillé le chef de la police de Virginia Beach, James Cervera. Quatre autres personnes blessées sont soignées dans les hôpitaux de la région et d’autres auraient pu s’y rendre par leurs propres moyens, a précisé le responsable policier. Il était peu après 16 heures vendredi (22 heures à Paris) quand le suspect, « un employé de longue date » est entré dans le bâtiment et a commencé « immédiatement à tirer à l’aveugle sur toutes les victimes », a raconté M. Cervera. Repérant l’étage du bâtiment où se trouvait le tireur par le bruit du sifflement des balles, les policiers sont intervenus. « C’était un long échange de coups de feu entre ces quatre policiers et le suspect. » Touché, le tireur a succombé à ses blessures. M. Cervera a précisé qu’un policier avait été « sauvé » par son gilet pare-balles. Sur place, les policiers ont retrouvé un pistolet avec de nombreux chargeurs vidés. Les lieux de la fusillade s’apparentent à une « zone de guerre », a estimé James Cervera. Article réservé à nos abonnés Lire aussi Fusillades et armes à feu aux Etats-Unis : la jeunesse en première ligne Des réactions, du maire de Virginia Beach à Pharrell Williams Informé de la tragédie, le président Donald Trump « continue à suivre la situation », a fait savoir la Maison Blanche. Le maire de la station balnéaire, Bobby Dyer, a parlé, devant les journalistes, « du jour le plus catastrophique de l’histoire de Virginia Beach ». « Je suis effondré », a réagi sur Twitter le sénateur démocrate de Virginie Tim Kaine. « Mon cœur est avec tous ceux qui ont perdu un être cher », a poursuivi l’ancien colistier d’Hillary Clinton à la présidentielle 2016. I’m devastated to learn of the tragic shooting tonight in Virginia Beach. My heart is with everyone who lost a love… https://t.co/iAf2IRKhd8 — timkaine (@Tim Kaine) « Nous prions pour notre ville, pour les vies perdues, pour leurs familles et tous ceux affectés », a tweeté le chanteur Pharrell Williams, originaire de Virginia Beach. « C’est inacceptable que l’Amérique reste l’unique pays développé où ceci est habituel. Nous devons agir », a estimé, sur Twitter, le candidat à l’investiture démocrate pour la présidentielle 2020 Pete Buttigieg. La Virginie, siège de la National Rifle Association Les Etats-Unis sont régulièrement endeuillés par les fusillades. Le 20 avril dernier, le pays a commémoré le vingtième anniversaire de la tuerie du lycée Columbine, où deux lycéens avaient ouvert le feu et tué douze de leurs camarades et un professeur. La question des violences armées prend une dimension particulière en Virginie, car c’est dans cet Etat que siège la National Rifle Association (NRA), le premier lobby des armes aux Etats-Unis. Cet Etat traditionnellement conservateur, mais qui se colore démocrate à mesure qu’il s’urbanise et se diversifie, a été le théâtre en 2007 d’une fusillade particulièrement meurtrière : un étudiant instable mentalement avait abattu 32 personnes sur le campus de l’université Virginia Tech.\n",
      "[['zone', 'bâtiment', 'municipal', 'Virginia', 'Beach', 'être', 'sécuriser'], ['Kaitlin', 'mckeown', 'AP'], ['personne', 'être', 'abattre', 'vendredi', '31', 'mai', 'tireur', 'bâtiment', 'municipal', 'Virginia', 'Beach', 'etat', 'virginie', 'station', 'balnéaire', 'côte', 'américain'], ['bilan', 'temps', 'établir', '11', 'mort', 'être', 'revoir', 'hausse', 'décès', 'victime', 'succomber', 'blessure', 'chemin', 'hôpital', 'détailler', 'chef', 'police', 'Virginia', 'Beach', 'James', 'Cervera'], ['personne', 'blesser', 'soigner', 'hôpital', 'région', 'propre', 'moyen', 'préciser', 'responsable', 'policier'], ['16', 'heure', 'vendredi', '22', 'heure', 'Paris', 'suspect', 'employé', 'long', 'date', 'entrer', 'bâtiment', 'commencer', 'immédiatement', 'tirer', 'aveugle', 'victime'], ['raconter', 'm.', 'Cervera'], ['repérant'], ['étage', 'bâtiment', 'trouver', 'tireur', 'bruit', 'sifflement', 'balle'], ['policier', 'intervenir'], ['long', 'échange', 'coup', 'feu', 'policier', 'suspect'], ['Touché', 'tireur', 'succomber', 'blessure'], ['m.', 'Cervera', 'préciser', 'policier', 'être', 'sauver', 'gilet', 'pare-balle'], ['place', 'policier', 'retrouver', 'pistolet', 'chargeur', 'vider'], ['lieu', 'fusillade', 'apparentent', 'zone', 'guerre', 'estimer', 'James', 'Cervera'], ['article', 'réserver', 'abonné'], ['lire'], ['fusillade', 'arme', 'feu', 'Etats-Unis', 'jeunesse', 'ligne', 'réaction', 'maire', 'Virginia'], ['Beach', 'Pharrell'], ['Williams', 'Informé', 'tragédie'], ['président', 'Donald', 'Trump', 'continue', 'situation'], ['savoir', 'Maison', 'Blanche'], ['maire', 'station', 'balnéaire', 'Bobby', 'Dyer', 'parler', 'journaliste', 'jour', 'catastrophique', 'histoire', 'Virginia', 'Beach'], ['effondré', 'réagir', 'twitter', 'sénateur', 'démocrate', 'virginie'], ['Tim', 'Kaine'], ['cœur', 'perdre', 'cher', 'poursuivre', 'ancien', 'colistier'], ['Hillary', 'Clinton', 'présidentielle', '2016'], ['i’', 'm', 'devastated', 'to', 'learn', 'of', 'the', 'tragic', 'shooting', 'tonight', 'in', 'Virginia', 'Beach'], ['My', 'heart', 'i', 'with', 'everyon', 'who', 'lost', 'love', 'https://t.co/iaf2irkhd8'], [], ['timkaine', '@Tim', 'Kaine'], ['prier', 'ville', 'vie', 'perdre', 'famille', 'affecté'], ['tweeter', 'chanteur', 'Pharrell', 'Williams', 'originaire', 'Virginia', 'Beach'], ['inacceptable', 'Amérique', 'unique'], ['pays', 'développé', 'habituel'], ['devoir', 'agir', 'estimer', 'Twitter', 'candidat', 'investiture', 'démocrate', 'présidentielle', '2020'], ['Pete', 'Buttigieg'], ['virginie', 'siège', 'national', 'rifle'], ['association'], ['Etats-Unis', 'régulièrement', 'endeuiller', 'fusillade'], ['20', 'avril', 'dernier', 'pays', 'commémorer', 'vingtième', 'anniversaire', 'tuerie', 'lycée', 'Columbine', 'lycéen', 'feu', 'tuer', 'camarade', 'professeur'], ['question', 'violence', 'armer', 'prendre', 'dimension', 'particulière', 'virginie', 'etat', 'siège', 'national', 'rifle', 'association', 'NRA', 'lobby', 'arme', 'etats-unis'], ['etat', 'traditionnellement', 'conservateur', 'colore', 'démocrate', 'mesure', 'urbanise', 'diversifier', 'être', 'théâtre', '2007', 'fusillade', 'particulièrement', 'meurtrier', 'étudiant', 'instable', 'mentalemer', 'abattre', '32', 'personne', 'campus', 'université', 'virginia', 'Tech']]\n"
     ]
    }
   ],
   "source": [
    "import summ.utils\n",
    "keyword_sentences = summ.utils.get_keyword_sentences(doc)\n",
    "print(article)\n",
    "print(keyword_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbc2d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "word_idx_to_sent = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44cab426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La zone du bâtiment municipal de Virginia Beach a été sécurisée.\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "sent = list(doc.sents)[0]\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c2b9a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at flaubert/flaubert_large_cased were not used when initializing FlaubertModel: ['pred_layer.proj.bias', 'pred_layer.proj.weight']\n",
      "- This IS expected if you are initializing FlaubertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FlaubertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "model = AutoModel.from_pretrained('flaubert/flaubert_large_cased')\n",
    "tokenizer = AutoTokenizer.from_pretrained('flaubert/flaubert_large_cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e72a084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['La</w>', 'zone</w>', 'du</w>', 'bâtiment</w>', 'municipal</w>', 'de</w>', 'Virginia</w>', 'Beach</w>', 'a</w>', 'été</w>', 'sécurisée</w>', '.</w>']\n"
     ]
    }
   ],
   "source": [
    "tokenized_sent = tokenizer.tokenize(sent.text)\n",
    "print(tokenized_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4828dd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sent = tokenizer.encode(tokenized_sent)\n",
    "sentence_embeds = flaubert_summ.get_sent_embeds(encoded_sent)\n",
    "print(sentence_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1ef149",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.fr.stop_words import STOP_WORDS\n",
    "import string\n",
    "\n",
    "for j, token in enumerate(tokenized_sent):\n",
    "    if not token in STOP_WORDS and token not in string.punctuation:\n",
    "        print(token)\n",
    "        embeddings.append(sentence_embeds[0][j].detach().numpy())\n",
    "        word_idx_to_sent.append((i, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a5f808",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f680a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, token in enumerate(tokenized_sent):\n",
    "    word_idx_to_sent.append((i, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e27f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_idx_to_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c35c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "sent = list(doc.sents)[0]\n",
    "tokenized_sent = flaubert_summ.tokenizer.tokenize(sent.text)\n",
    "print(tokenized_sent)\n",
    "encoded_sentence = tokenizer.encode(tokenized_sent, is_split_into_words=True)\n",
    "print(encoded_sentence)\n",
    "res = model(torch.tensor([encoded_sentence]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe05841",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(encoded_sentence))\n",
    "print(len(sent))\n",
    "print(res.last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be852dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "\n",
    "for i, sent in enumerate(doc.sents):\n",
    "    tokenized_sent = flaubert_summ.tokenizer.tokenize(sent.text)\n",
    "\n",
    "    if not tokenized_sent:\n",
    "        continue\n",
    "\n",
    "    sentence_embeds = flaubert_summ.get_sent_embeds(tokenized_sent)\n",
    "    embeddings.extend(torch.unbind(sentence_embeds[0].detach()))\n",
    "\n",
    "    for j, token in enumerate(tokenized_sent):\n",
    "        word_idx_to_sent.append((i, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7879c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(embeddings))\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b40916",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "stacked = torch.stack(embeddings)\n",
    "print(stacked.shape)\n",
    "print(len(word_idx_to_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8354e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 5\n",
    "print(stacked[id])\n",
    "sent = list(doc.sents)[id]\n",
    "tokenized_sent = flaubert_summ.tokenizer.tokenize(sent.text)\n",
    "encoded_sentence = tokenizer.encode(tokenized_sent, is_split_into_words=True)\n",
    "print(encoded_sentence)\n",
    "for token in tokenized_sent:\n",
    "    print(token)\n",
    "print(len(encoded_sentence))\n",
    "print(len(tokenized_sent))\n",
    "# from sklearn.cluster import KMeans\n",
    "# kmeans = KMeans(n_clusters=5).fit(stacked)\n",
    "# embed_labels = kmeans.labels_\n",
    "# centroids = kmeans.cluster_centers_\n",
    "# print(embed_labels, centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0e5dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encoded_sentence[2])\n",
    "print(encoded_sentence[7])\n",
    "print(encoded_sentence[12])\n",
    "print(stacked[2])\n",
    "print(stacked[7])\n",
    "print(stacked[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8312f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenized_sent)\n",
    "l = []\n",
    "for token in tokenized_sent:\n",
    "    l += tokenizer.encode(token, is_split_into_words=True)[1:-1]\n",
    "l = [0] + l + [1]\n",
    "print(l)\n",
    "print(tokenizer.encode(tokenized_sent, is_split_into_words=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2da287",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_emb = flaubert_summ.get_sent_embeds(tokenized_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0938f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sent_emb.shape)\n",
    "encoded = tokenizer.encode(tokenized_sent, split_into_words=True)\n",
    "print(len(encoded))\n",
    "print(encoded)\n",
    "print(tokenized_sent)\n",
    "print(len(tokenized_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae2598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 5\n",
    "sent = list(doc.sents)[id]\n",
    "tokenized_sent = tokenizer.tokenize(sent.text)\n",
    "encoded = tokenizer.encode(tokenized_sent, split_into_words=True)\n",
    "print(encoded)\n",
    "print(len(encoded))\n",
    "sent_emb = model(torch.tensor([encoded]))[0]\n",
    "print(sent_emb.shape)\n",
    "print(sent_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f882b24f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
