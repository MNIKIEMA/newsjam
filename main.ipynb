{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feaed337",
   "metadata": {},
   "source": [
    "## ONLY if running on Colaboratory, run this cell first (once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75f9491",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/pie3636/newsjam.git\n",
    "!mv newsjam/* ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad23b536",
   "metadata": {},
   "source": [
    "## Install missing modules if needed (only run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ceafccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-score\n",
      "  Downloading bert_score-0.3.11-py3-none-any.whl (60 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-1.17.0-py3-none-any.whl (306 kB)\n",
      "Collecting gensim\n",
      "  Downloading gensim-4.1.2.tar.gz (23.2 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: matplotlib in c:\\users\\pc hp 2020\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 4)) (3.5.1)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.6.7-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\pc hp 2020\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 6)) (1.22.0)\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-3.19.1-py2.py3-none-any.whl (162 kB)\n",
      "Collecting rouge-score\n",
      "  Downloading rouge_score-0.0.4-py2.py3-none-any.whl (22 kB)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96.tar.gz (508 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.2.1-cp310-cp310-win_amd64.whl (11.9 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement torch (from versions: none)\n",
      "ERROR: No matching distribution found for torch\n",
      "C:\\Users\\PC HP 2020\\AppData\\Local\\Programs\\Python\\Python310\\python.exe: No module named spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install -r requirements.txt\n",
    "!python -m spacy download fr_core_news_sm\n",
    "# Note: You'll have to restart the kernel/runtime after running this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6422ab",
   "metadata": {},
   "source": [
    "## Imports (only run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f9c5abd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\PCHP20~1\\AppData\\Local\\Temp/ipykernel_3836/2018602333.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# MLSUM Corpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Loading article data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "# MLSUM Corpus\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Loading article data\n",
    "import json\n",
    "\n",
    "# Our packages\n",
    "from eval.rouge_l import RougeLEval\n",
    "from eval.bert_eval import BERT_Eval\n",
    "from eval.time import TimeEval\n",
    "\n",
    "from summ.lsa import LSASummarizer\n",
    "from summ.bert_embed import BertEmbeddingsSummarizer\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "dataset = load_dataset('mlsum', 'fr')\n",
    "\n",
    "rouge_l = RougeLEval()\n",
    "bert = BERT_Eval()\n",
    "timer = TimeEval()\n",
    "lsa_summ = LSASummarizer()\n",
    "flaubert_summ = BertEmbeddingsSummarizer('flaubert/flaubert_large_cased')\n",
    "camembert_summ = BertEmbeddingsSummarizer('camembert/camembert-large')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e57dfaa",
   "metadata": {},
   "source": [
    "## Summarize a single article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3bdf0df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pick an article and its reference summary\n",
    "article = dataset['test']['text'][54]\n",
    "ref_summ = dataset['test']['summary'][54]\n",
    "\n",
    "# Computes the summary and evaluation\n",
    "# timer.evaluate_one(article, BertEmbeddingsSummarizer, 'camembert/camembert-large')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b30944c",
   "metadata": {},
   "source": [
    "## Summarize a series of articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cf57c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = dataset['test']['text'][:10]\n",
    "ref_summs = dataset['test']['summary'][:10]\n",
    "\n",
    "# Here we pick 5 articles\n",
    "# gen_summs = []\n",
    "# for text in tqdm(texts[:5]):\n",
    "#     gen_summs.append(flaubert_summ.get_summary(text))\n",
    "\n",
    "# scores1, scores2 = rouge_l.evaluate_many(ref_summs, gen_summs, 5)\n",
    "# results = rouge_l.get_results(scores1, scores2)\n",
    "\n",
    "# for k, v in results.items():\n",
    "#     print(k.ljust(25), round(v*100, 3), '%')\n",
    "\n",
    "timer.evaluate_many(texts, LSASummarizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bb0d4b",
   "metadata": {},
   "source": [
    "#### Optional: Save generated summaries to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8fa0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('generated.txt', 'w') as f:\n",
    "    for summ1, summ2 in tqdm(gen_summs):\n",
    "        f.write(summ1)\n",
    "        f.write('\\n\\n')\n",
    "        f.write(summ2)\n",
    "        f.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368b970a",
   "metadata": {},
   "source": [
    "## Summarize a series of scraped articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e78b51",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open('data/actu_preliminary.json', 'r', encoding='utf-8') as jsonfile:\n",
    "    data = json.load(jsonfile)\n",
    "\n",
    "texts = [article['text'] for article in data]\n",
    "ref_summs = [article['summary'] for article in data]\n",
    "\n",
    "gen_summs = []\n",
    "for text in tqdm(texts):\n",
    "    gen_summs.append(flaubert_summ.get_summary(text))\n",
    "\n",
    "scores1, scores2 = rouge_l.evaluate_many(ref_summs, gen_summs)\n",
    "results = rouge_l.get_results(scores1, scores2)\n",
    "\n",
    "for k, v in results.items():\n",
    "    print(k.ljust(25), round(v*100, 3), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b002dada",
   "metadata": {},
   "source": [
    "Implementation of BERTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643d3342",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_summs, short_summs, ref_summs, key_ref_sums =  bert.split_summs(gen_summs, ref_summs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0d9ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert.bert_score(long_summs, short_summs, ref_summs, key_ref_sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7715e238",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert.get_matrix(long_summs, ref_summs, 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
