{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27dbf674",
   "metadata": {},
   "source": [
    "## Imports (needs to be run only once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f9c5abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset mlsum (C:\\Users\\maxim\\.cache\\huggingface\\datasets\\mlsum\\fr\\1.0.0\\77f23eb185781f439927ac2569ab1da1083195d8b2dab2b2f6bbe52feb600688)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3b480609a974cb7af679b740cdd8a76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For the first execution, you will need to uncomment this line\n",
    "# to download the SpaCy model and other necessary packages. Then you can comment it back\n",
    "# !python -m spacy download fr_core_news_sm\n",
    "# !python -m pip install ipynb\n",
    "\n",
    "# MLSUM Corpus\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Loading article data\n",
    "import json\n",
    "\n",
    "# Our packages\n",
    "from eval.rouge_l import RougeLEval\n",
    "from summ.lsa import LSASummarizer\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "dataset = load_dataset('mlsum', 'fr')\n",
    "\n",
    "rouge_l = RougeLEval()\n",
    "lsa_summ = LSASummarizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492252fe",
   "metadata": {},
   "source": [
    "## Summarize a single article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3bdf0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les secours ont été prévenus vers 5 heures du matin, mais \"l'incendie avait déjà bien démarré\", a-t-il expliqué.\n",
      "\n",
      "secours être prévenir 5 heure matin incendie bien démarrer -t il expliquer\n",
      "\n",
      "Cinq personnes sont mortes, et treize autres ont été blessées à Nîmes, dans le Gard, dans un incendie qui s'est déclenché vendredi 1er janvier au petit matin.\n",
      "\n",
      "{'rougeL': Score(precision=0.16666666666666666, recall=0.13333333333333333, fmeasure=0.14814814814814814)}\n",
      "{'rougeL': Score(precision=0.21428571428571427, recall=0.2, fmeasure=0.20689655172413796)}\n"
     ]
    }
   ],
   "source": [
    "# Pick an article and its reference summary\n",
    "article = dataset['train']['text'][4]\n",
    "ref_summ = dataset['train']['summary'][4]\n",
    "\n",
    "# Computes the summary and evaluation\n",
    "gen_summ = lsa_summ.get_summary(article)\n",
    "scores1, scores2 = rouge_l.evaluate_one(ref_summ, gen_summ)\n",
    "print(gen_summ[0])\n",
    "print()\n",
    "print(gen_summ[1])\n",
    "print()\n",
    "print(ref_summ)\n",
    "print()\n",
    "print(scores1)\n",
    "print(scores2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281c2ecc",
   "metadata": {},
   "source": [
    "## Summarize a series of articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d8afe06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:22<00:00, 16.51s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 43.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long precision avg        16.959 %\n",
      "Keyword precision avg     18.962 %\n",
      "Long recall avg           17.561 %\n",
      "Keyword recall avg        8.933 %\n",
      "Long F1-score avg         12.231 %\n",
      "Keyword F1-score avg      9.841 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "texts = dataset['test']['text']\n",
    "ref_summs = dataset['test']['summary']\n",
    "\n",
    "# Here we pick 5 articles\n",
    "gen_summs = []\n",
    "for text in tqdm(texts[:5]):\n",
    "    gen_summs.append(lsa_summ.get_summary(text))\n",
    "\n",
    "scores1, scores2 = rouge_l.evaluate_many(ref_summs, gen_summs, 5)\n",
    "results = rouge_l.get_results(scores1, scores2)\n",
    "\n",
    "for k, v in results.items():\n",
    "    print(k.ljust(25), round(v*100, 3), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6ed9dc",
   "metadata": {},
   "source": [
    "#### Optional: Save generated summaries to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65bd77b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('generated.txt', 'w') as f:\n",
    "    for summ1, summ2 in tqdm(gen_summs):\n",
    "        f.write(summ1)\n",
    "        f.write('\\n\\n')\n",
    "        f.write(summ2)\n",
    "        f.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ae31ee",
   "metadata": {},
   "source": [
    "## Summarize a series of scraped articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5c30908",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [14:35<00:00, 18.63s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:00<00:00, 64.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long precision avg        54.567 %\n",
      "Keyword precision avg     63.049 %\n",
      "Long recall avg           57.536 %\n",
      "Keyword recall avg        52.699 %\n",
      "Long F1-score avg         63.779 %\n",
      "Keyword F1-score avg      56.84 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open('data/actu_preliminary.json', 'r', encoding='utf-8') as jsonfile:\n",
    "    data = json.load(jsonfile)\n",
    "\n",
    "texts = [article['text'] for article in data]\n",
    "ref_summs = [article['summary'] for article in data]\n",
    "\n",
    "gen_summs = []\n",
    "for text in tqdm(texts):\n",
    "    gen_summs.append(lsa_summ.get_summary(text))\n",
    "\n",
    "scores1, scores2 = rouge_l.evaluate_many(ref_summs, gen_summs)\n",
    "results = rouge_l.get_results(scores1, scores2)\n",
    "\n",
    "for k, v in results.items():\n",
    "    print(k.ljust(25), round(v*100, 3), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36601e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
