{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feaed337",
   "metadata": {},
   "source": [
    "## ONLY if running on Colaboratory, run this cell first (once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75f9491",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/pie3636/newsjam.git\n",
    "!mv newsjam/* ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad23b536",
   "metadata": {},
   "source": [
    "## Install missing modules if needed (only run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceafccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install -r requirements.txt\n",
    "!python -m spacy download fr_core_news_sm\n",
    "!python -m spacy download en_core_web_sm\n",
    "# Note: You'll have to restart the kernel/runtime after running this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6422ab",
   "metadata": {},
   "source": [
    "## Imports (only run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f9c5abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset mlsum (/Users/josephkeenan/.cache/huggingface/datasets/mlsum/fr/1.0.0/77f23eb185781f439927ac2569ab1da1083195d8b2dab2b2f6bbe52feb600688)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bebadbcece5b4ce58dfa65dffc92ee59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset cnn_dailymail (/Users/josephkeenan/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97201b7c10a74051b46fe37295b67976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at flaubert/flaubert_large_cased were not used when initializing FlaubertModel: ['pred_layer.proj.bias', 'pred_layer.proj.weight']\n",
      "- This IS expected if you are initializing FlaubertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FlaubertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at camembert/camembert-large were not used when initializing CamembertModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing CamembertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# MLSUM Corpus & CNN/Daily Mail Corpus\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Loading article data\n",
    "import json\n",
    "\n",
    "# Our packages\n",
    "from eval.rouge_l import RougeLEval\n",
    "from eval.bert_eval import BERT_Eval\n",
    "from eval.time import TimeEval\n",
    "\n",
    "from summ.lsa import LSASummarizer\n",
    "from summ.bert_embed import BertEmbeddingsSummarizer\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "dataset_fr = load_dataset('mlsum', 'fr')\n",
    "dataset_en = load_dataset('cnn_dailymail', '3.0.0')\n",
    "\n",
    "rouge_l = RougeLEval()\n",
    "bert = BERT_Eval()\n",
    "timer = TimeEval()\n",
    "lsa_summ = LSASummarizer()\n",
    "flaubert_summ = BertEmbeddingsSummarizer('flaubert/flaubert_large_cased')\n",
    "camembert_summ = BertEmbeddingsSummarizer('camembert/camembert-large')\n",
    "roberta_summ = BertEmbeddingsSummarizer('roberta-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e57dfaa",
   "metadata": {},
   "source": [
    "## Summarize a single article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3bdf0df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pick an article and its reference summary\n",
    "article_fr = dataset_fr['test']['text'][54]\n",
    "ref_summ_fr = dataset_fr['test']['summary'][54]\n",
    "\n",
    "article_en = dataset_en['test']['article'][43]\n",
    "ref_summ_en = dataset_en['test']['highlights'][43]\n",
    "\n",
    "# Computes the summary and evaluation\n",
    "# timer.evaluate_one(article, BertEmbeddingsSummarizer, 'camembert/camembert-large')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b30944c",
   "metadata": {},
   "source": [
    "## Summarize a series of French articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9cf57c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 15/15 [05:42<00:00, 22.81s/it]\n",
      "100%|███████████████████████████████████████████| 15/15 [00:00<00:00, 75.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long precision avg        10.413 %\n",
      "Long recall avg           11.466 %\n",
      "Long F1-score avg         10.771 %\n",
      "Keyword precision avg     6.782 %\n",
      "Keyword recall avg        8.435 %\n",
      "Keyword F1-score avg      7.314 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Here we pick the number of articles\n",
    "num_articles = 15\n",
    "\n",
    "texts = dataset_fr['test']['text'][:num_articles]\n",
    "ref_summs = dataset_fr['test']['summary'][:num_articles]\n",
    "\n",
    "gen_summs = []\n",
    "for text in tqdm(texts[:num_articles]):\n",
    "     gen_summs.append(flaubert_summ.get_summary(text))\n",
    "\n",
    "scores1, scores2 = rouge_l.evaluate_many(ref_summs, gen_summs, num_articles)\n",
    "results = rouge_l.get_results(scores1, scores2)\n",
    "\n",
    "for k, v in results.items():\n",
    "     print(k.ljust(25), round(v*100, 3), '%')\n",
    "\n",
    "#timer.evaluate_many(texts, LSASummarizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d2e970a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tsitsipas, Halep, Fognini et Zverev ont gagné leurs matchs. « Le Monde » livre les résultats en détail au fil de la journée.\n",
      "\n",
      "Fabio Fognini est venu à bout de l’Espagnol en quatre sets (7-6, 6-4, 4-6, 6-1).\n",
      "Le jeune Grec, classé 6e mondial à 20 ans, a fini par s’imposer 7-5, 6-3, 6-7 [5], 7-6 [6] contre le Serbe.\n",
      "\n",
      "Fabio Fognini venir bout Espagnol set 7 6 6 4 4 6 6 1\n",
      "jeune Grec classer sixième mondial 20 an finir imposer 7 5 6 3 6 7 5 7 6 6 contre serbe\n"
     ]
    }
   ],
   "source": [
    "num = 12\n",
    "\n",
    "print(ref_summs[num])\n",
    "print()\n",
    "print(gen_summs[num][0])\n",
    "print()\n",
    "print(gen_summs[num][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768d84b3",
   "metadata": {},
   "source": [
    "## Summarize a series of English articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2aa8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████████████████████▌                       | 7/15 [00:37<00:42,  5.35s/it]"
     ]
    }
   ],
   "source": [
    "# Here we pick the number of articles\n",
    "num_articles = 15\n",
    "\n",
    "texts = dataset_en['test']['article'][:num_articles]\n",
    "ref_summs = dataset_en['test']['highlights'][:num_articles]\n",
    "\n",
    "gen_summs = []\n",
    "for text in tqdm(texts[:num_articles]):\n",
    "     gen_summs.append(roberta_summ.get_summary(text, lang='en'))\n",
    "\n",
    "scores1, scores2 = rouge_l.evaluate_many(ref_summs, gen_summs, num_articles)\n",
    "results = rouge_l.get_results(scores1, scores2)\n",
    "\n",
    "for k, v in results.items():\n",
    "     print(k.ljust(25), round(v*100, 3), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "60ea48f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saudi general says more than 1,200 airstrikes since campaign began March 26 .\n",
      "Three Saudis were killed in attack on border position, source tells CNN .\n",
      "\n",
      "(CNN)More than 500 Houthi rebels have been killed since the start of Saudi-led military operations against Yemeni Shia fighters, a Saudi Defense Ministry official said Saturday, according to the state-run Saudi Press Agency.\n",
      "\n",
      "CNN)More 500 Houthi rebel kill start Saudi lead military operation yemeni Shia fighter Saudi Defense Ministry official say Saturday accord state run Saudi Press Agency\n"
     ]
    }
   ],
   "source": [
    "num = 12\n",
    "\n",
    "print(ref_summs[num])\n",
    "print()\n",
    "print(gen_summs[num][0])\n",
    "print()\n",
    "print(gen_summs[num][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bb0d4b",
   "metadata": {},
   "source": [
    "#### Optional: Save generated summaries to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8fa0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('generated.txt', 'w') as f:\n",
    "    for summ1, summ2 in tqdm(gen_summs):\n",
    "        f.write(summ1)\n",
    "        f.write('\\n\\n')\n",
    "        f.write(summ2)\n",
    "        f.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368b970a",
   "metadata": {},
   "source": [
    "## Summarize a series of scraped articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "55e78b51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 47/47 [01:16<00:00,  1.63s/it]\n",
      "100%|██████████████████████████████████████████| 47/47 [00:00<00:00, 101.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long precision avg        49.216 %\n",
      "Long recall avg           62.04 %\n",
      "Long F1-score avg         54.236 %\n",
      "Keyword precision avg     48.435 %\n",
      "Keyword recall avg        61.659 %\n",
      "Keyword F1-score avg      53.56 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open('data/actu_preliminary.json', 'r', encoding='utf-8') as jsonfile:\n",
    "    data = json.load(jsonfile)\n",
    "\n",
    "texts = [article['text'] for article in data]\n",
    "ref_summs = [article['summary'] for article in data]\n",
    "\n",
    "gen_summs = []\n",
    "for text in tqdm(texts):\n",
    "    gen_summs.append(lsa_summ.get_summary(text))\n",
    "\n",
    "scores1, scores2 = rouge_l.evaluate_many(ref_summs, gen_summs)\n",
    "results = rouge_l.get_results(scores1, scores2)\n",
    "\n",
    "for k, v in results.items():\n",
    "    print(k.ljust(25), round(v*100, 3), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b002dada",
   "metadata": {},
   "source": [
    "## Implementation of BERTScore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6113bdc3",
   "metadata": {},
   "source": [
    "Splitting summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "643d3342",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_summs, short_summs, ref_summs, key_ref_summs =  bert.split_summs(gen_summs, ref_summs, gen_keys=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d3c58d",
   "metadata": {},
   "source": [
    "Computation of BERTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb0d9ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccc0e25e3f58404da0594a8add9e3fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d61c9656df3049f3ab326a4a2d58b0b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 18.72 seconds, 2.51 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e2c1faaefa4c5ea8b0eecbc5b9ea36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26bcd77e066447399908fc147ac6b1ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 12.90 seconds, 3.64 sentences/sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Long precision avg': '0.2326',\n",
       " 'Long recall avg': '0.3982',\n",
       " 'Long F1-score avg': '0.3125',\n",
       " 'Keyword precision avg': '0.2440',\n",
       " 'Keyword recall avg': '0.3905',\n",
       " 'Keyword F1-score avg': '0.3151'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert.bert_score(long_summs, short_summs, ref_summs, key_ref_summs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07705484",
   "metadata": {},
   "source": [
    "Optional matrix of a score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7715e238",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert.get_matrix(long_summs, ref_summs, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475cc9fb",
   "metadata": {},
   "source": [
    "Experimentation w/ BERTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cbfcdac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "test_gen_summ = []\n",
    "test_gen_summ.append('B')\n",
    "print(len(test_gen_summ[0]))\n",
    "\n",
    "print()\n",
    "\n",
    "test_ref_summ = []\n",
    "test_ref_summ.append('汉字')\n",
    "print(len(test_ref_summ[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5c8f562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d160f3f7b3e4dc9a18de0e1ef140e7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f03a8b866a6478d8a902c0ce5a23d4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 0.13 seconds, 7.84 sentences/sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Long precision avg': '0.3093',\n",
       " 'Long recall avg': '0.2388',\n",
       " 'Long F1-score avg': '0.2743'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert.bert_score(test_gen_summ, test_ref_summ)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
