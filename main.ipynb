{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27dbf674",
   "metadata": {},
   "source": [
    "## Imports (needs to be run only once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f9c5abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset mlsum (C:\\Users\\maxim\\.cache\\huggingface\\datasets\\mlsum\\fr\\1.0.0\\77f23eb185781f439927ac2569ab1da1083195d8b2dab2b2f6bbe52feb600688)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea0f57c246d64d79989f9fac985b9194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at flaubert/flaubert_large_cased were not used when initializing FlaubertModel: ['pred_layer.proj.weight', 'pred_layer.proj.bias']\n",
      "- This IS expected if you are initializing FlaubertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FlaubertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at camembert/camembert-large were not used when initializing CamembertModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing CamembertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# If you ever get any error, try uncommenting these two lines\n",
    "# to download the required SpaCy model and other Python libraries packages.\n",
    "# Then you can comment them back\n",
    "# !python -m spacy download fr_core_news_sm\n",
    "# !python -m pip install -r requirements.txt\n",
    "\n",
    "# MLSUM Corpus\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Loading article data\n",
    "import json\n",
    "\n",
    "# Our packages\n",
    "from eval.rouge_l import RougeLEval\n",
    "from summ.lsa import LSASummarizer\n",
    "from summ.bert_embed import BertEmbeddingsSummarizer\n",
    "\n",
    "# BERTScore import\n",
    "# you can install this package by running pip install bert-score\n",
    "from bert_score import BERTScorer\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "dataset = load_dataset('mlsum', 'fr')\n",
    "\n",
    "rouge_l = RougeLEval()\n",
    "lsa_summ = LSASummarizer()\n",
    "flaubert_summ = BertEmbeddingsSummarizer('flaubert/flaubert_large_cased')\n",
    "camembert_summ = BertEmbeddingsSummarizer('camembert/camembert-large')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492252fe",
   "metadata": {},
   "source": [
    "## Summarize a single article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3bdf0df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "» Touché, le tireur a succombé à ses blessures.\n",
      "Tim Kaine.\n",
      ", a raconté M. Cervera.\n",
      "Kaitlin McKeown / AP\n",
      "Repérant l’\n",
      "Article réservé à nos abonnés\n",
      "\n",
      "Touché tireur succomber blessure\n",
      "Tim Kaine\n",
      "raconter m. Cervera\n",
      "Kaitlin mckeown AP\n",
      "repérant\n",
      "article réserver abonné\n",
      "\n",
      "Le suspect principal, un employé des services de la ville, a tiré « à l’aveugle ». Il est lui aussi décédé.\n",
      "\n",
      "{'rougeL': Score(precision=0.12, recall=0.14285714285714285, fmeasure=0.13043478260869565)}\n",
      "{'rougeL': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n"
     ]
    }
   ],
   "source": [
    "# Pick an article and its reference summary\n",
    "article = dataset['test']['text'][54]\n",
    "ref_summ = dataset['test']['summary'][54]\n",
    "\n",
    "# Computes the summary and evaluation\n",
    "gen_summ = flaubert_summ.get_summary(article)\n",
    "scores1, scores2 = rouge_l.evaluate_one(ref_summ, gen_summ)\n",
    "print(gen_summ[0])\n",
    "print()\n",
    "print(gen_summ[1])\n",
    "print()\n",
    "print(ref_summ)\n",
    "print()\n",
    "print(scores1)\n",
    "print(scores2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281c2ecc",
   "metadata": {},
   "source": [
    "## Summarize a series of articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d8afe06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [06:51<00:00, 82.33s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long precision avg        10.628 %\n",
      "Long recall avg           9.801 %\n",
      "Long F1-score avg         10.176 %\n",
      "Keyword precision avg     5.288 %\n",
      "Keyword recall avg        4.038 %\n",
      "Keyword F1-score avg      4.538 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "texts = dataset['test']['text']\n",
    "ref_summs = dataset['test']['summary']\n",
    "\n",
    "# Here we pick 5 articles\n",
    "gen_summs = []\n",
    "for text in tqdm(texts[:5]):\n",
    "    gen_summs.append(flaubert_summ.get_summary(text))\n",
    "\n",
    "scores1, scores2 = rouge_l.evaluate_many(ref_summs, gen_summs, 5)\n",
    "results = rouge_l.get_results(scores1, scores2)\n",
    "\n",
    "for k, v in results.items():\n",
    "    print(k.ljust(25), round(v*100, 3), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6ed9dc",
   "metadata": {},
   "source": [
    "#### Optional: Save generated summaries to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bd77b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('generated.txt', 'w') as f:\n",
    "    for summ1, summ2 in tqdm(gen_summs):\n",
    "        f.write(summ1)\n",
    "        f.write('\\n\\n')\n",
    "        f.write(summ2)\n",
    "        f.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ae31ee",
   "metadata": {},
   "source": [
    "## Summarize a series of scraped articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c30908",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/actu_preliminary.json', 'r', encoding='utf-8') as jsonfile:\n",
    "    data = json.load(jsonfile)\n",
    "\n",
    "texts = [article['text'] for article in data]\n",
    "ref_summs = [article['summary'] for article in data]\n",
    "\n",
    "gen_summs = []\n",
    "for text in tqdm(texts):\n",
    "    gen_summs.append(lsa_summ.get_summary(text))\n",
    "\n",
    "scores1, scores2 = rouge_l.evaluate_many(ref_summs, gen_summs)\n",
    "results = rouge_l.get_results(scores1, scores2)\n",
    "\n",
    "for k, v in results.items():\n",
    "    print(k.ljust(25), round(v*100, 3), '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
