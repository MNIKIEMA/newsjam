{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scraper_functions.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAmWFaBGNsrV"
      },
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from itertools import groupby\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "import re\n",
        "import sys\n",
        "\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver') #make sure the webdriver is in the right spot\n",
        "\n",
        "def actu_scraper(url):\n",
        "    '''\n",
        "    takes a given URL, grabs the article text\n",
        "    returns the text as a string\n",
        "    '''\n",
        "    #webdriver initialization stuff\n",
        "    options = webdriver.ChromeOptions()\n",
        "    options.add_argument('--headless')\n",
        "    options.add_argument('--no-sandbox')\n",
        "    options.add_argument('--disable-dev-shm-usage')\n",
        "    driver = webdriver.Chrome('chromedriver',options=options)\n",
        "    driver.get(url)\n",
        "\n",
        "    #bypasses the cookie popup and grabs the article\n",
        "    try:\n",
        "      button = driver.find_element(By.CSS_SELECTOR, \"#didomi-notice-agree-button\")\n",
        "      button.click()\n",
        "    except:\n",
        "      article = driver.find_elements(By.XPATH, '/html/body/div[2]/main/div/div[1]/div[1]')\n",
        "    article = driver.find_elements(By.XPATH, '/html/body/div[2]/main/div/div[1]/div[1]')\n",
        "    article_text = []\n",
        "    \n",
        "    #article text cleanup, automatically removes all image captions, extraneous information at the start and end of every article, etc.\n",
        "    for x in range(len(article)):\n",
        "        article_text.append(article[x].text.replace(\"\\n\",\" \"))\n",
        "        article_text[x] = re.sub(r'Par.*\\d{1,2}:\\d{1,2}|Cet article vous a été.*|\\(©.*?\\)|<a.*?a>',\"\",article_text[x])\n",
        "    driver.close()\n",
        "    return article_text[x]\n",
        "\n",
        "def actu_autoscraper(url, url_amount=5):\n",
        "    '''\n",
        "    grab the given amount of URLs from an actu.fr list of articles and return them as a list\n",
        "    '''\n",
        "    url_list = []\n",
        "    options = webdriver.ChromeOptions()\n",
        "    options.add_argument('--headless')\n",
        "    options.add_argument('--no-sandbox')\n",
        "    options.add_argument('--disable-dev-shm-usage')\n",
        "    driver = webdriver.Chrome('chromedriver',options=options)\n",
        "    driver.get(url)\n",
        "    element = driver.find_element(By.XPATH, '/html/body/div[2]/main/div/div[2]/div/div/ul').find_elements(By.TAG_NAME, 'a')\n",
        "    for x in range(url_amount):\n",
        "      url_list.append(element[x].get_attribute(\"href\"))\n",
        "    return url_list"
      ]
    }
  ]
}